{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from subprocess import call\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bash Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./india_info.csv\")\n",
    "india_info = df[[\"state\", \"city\"]]\n",
    "bash_command_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in india_info.iterrows():\n",
    "    state, city = row[\"state\"], row[\"city\"]\n",
    "    temp = \"twint -s 'Unlock1 AND {}' -o 'output/{}--{}.csv' --csv\".format(\n",
    "        city, state, city\n",
    "    )\n",
    "    bash_command_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "file_temp = open(\"bash_command_list.txt\", \"w\")\n",
    "file_temp.writelines(bash_command_list)\n",
    "file_temp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bash_command in bash_command_list:\n",
    "    call(bash_command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapped_data = os.listdir(\"./output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame()\n",
    "\n",
    "for file in scrapped_data:\n",
    "    file_df = pd.read_csv(\"output/{}\".format(file))\n",
    "\n",
    "    temp = file.split(\".\")[0].split(\"--\")\n",
    "    state, city = temp[0], temp[1]\n",
    "\n",
    "    file_df[\"state\"] = state\n",
    "    file_df[\"city\"] = city\n",
    "\n",
    "    output_df = output_df.append(file_df)\n",
    "\n",
    "output_df = output_df.reset_index()\n",
    "\n",
    "df_to_work_with = output_df[[\"tweet\", \"link\", \"date\", \"time\", \"state\", \"city\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                                   tweet  \\\n",
       "0     No. of Containment Zones in Vijayawada (VMC li...   \n",
       "1     'Unlock 1.0' evokes huge response #Covid-19 #U...   \n",
       "2     Are people hesitant to venture out? Mall in Vi...   \n",
       "3     Minister Vellampalli Srinivas inspects arrange...   \n",
       "4     In Pics: With relaxations given to restaurants...   \n",
       "...                                                 ...   \n",
       "6778  स्वास्थ्य सेवाकर्मियों के साथ भेदभाव न करें। त...   \n",
       "6779  #IndiaFightsCorona\\n\\nआपस में उचित दूरी रखते ह...   \n",
       "6780  #IndiaFightsCorona\\n\\nखुले में थूकना स्वास्थ्य...   \n",
       "6781  30 जून तक बढ़ा लॉकडाउन, साथ मे शर्त के साथ ये ...   \n",
       "6782  City Center Korba is open from 10 am to 9 pm w...   \n",
       "\n",
       "                                                   link        date      time  \\\n",
       "0     https://twitter.com/tharunboda/status/12703037...  2020-06-09  16:06:29   \n",
       "1     https://twitter.com/TheHansIndiaWeb/status/127...  2020-06-09  02:59:26   \n",
       "2     https://twitter.com/NewIndianXpress/status/126...  2020-06-08  19:44:56   \n",
       "3     https://twitter.com/TheHansIndiaWeb/status/126...  2020-06-08  11:55:51   \n",
       "4     https://twitter.com/xpressandhra/status/126986...  2020-06-08  10:57:14   \n",
       "...                                                 ...         ...       ...   \n",
       "6778  https://twitter.com/FOB_Bhagalpur/status/12680...  2020-06-03  13:55:16   \n",
       "6779  https://twitter.com/FOB_Bhagalpur/status/12680...  2020-06-03  13:06:07   \n",
       "6780  https://twitter.com/FOB_Bhagalpur/status/12680...  2020-06-03  11:59:13   \n",
       "6781  https://twitter.com/ArrahCity/status/126673602...  2020-05-30  19:49:37   \n",
       "6782  https://twitter.com/CityCenterKorba/status/127...  2020-06-28  13:14:46   \n",
       "\n",
       "               state        city  \n",
       "0     Andhra Pradesh  Vijayawada  \n",
       "1     Andhra Pradesh  Vijayawada  \n",
       "2     Andhra Pradesh  Vijayawada  \n",
       "3     Andhra Pradesh  Vijayawada  \n",
       "4     Andhra Pradesh  Vijayawada  \n",
       "...              ...         ...  \n",
       "6778           Bihar   Bhagalpur  \n",
       "6779           Bihar   Bhagalpur  \n",
       "6780           Bihar   Bhagalpur  \n",
       "6781           Bihar       Arrah  \n",
       "6782    Chhattisgarh       Korba  \n",
       "\n",
       "[6783 rows x 6 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_work_with.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./model/model_v6.h5\")\n",
    "tokenizer = pickle.load(open(\"./model/tokenizer_v6.pickle\", \"rb\"))\n",
    "score_list = [\"anger\", \"happiness\", \"neutral\", \"sadness\", \"worry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(tweet):\n",
    "    sequences = tokenizer.texts_to_sequences([row[\"tweet\"]])\n",
    "    new_processed = pad_sequences(sequences, padding=\"post\", maxlen=30)\n",
    "    return model.predict(new_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6783it [07:42, 14.67it/s]\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame()\n",
    "\n",
    "for index, row in tqdm(\n",
    "    df_to_work_with[[\"date\", \"time\", \"tweet\",\n",
    "                     \"link\", \"state\", \"city\"]].iterrows()\n",
    "):\n",
    "\n",
    "    #if index % 20 == 0:\n",
    "        #print(\"At Index: {}\".format(index))\n",
    "\n",
    "    date = row[\"date\"]\n",
    "    time = row[\"time\"]\n",
    "\n",
    "    date_time = date + \" \" + time\n",
    "    date_time = datetime.datetime.strptime(date_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    tweet = row[\"tweet\"]\n",
    "    link = row[\"link\"]\n",
    "    state = row[\"state\"]\n",
    "    city = row[\"city\"]\n",
    "\n",
    "    score = analyze(tweet)\n",
    "\n",
    "    anger = score[0][0]\n",
    "    happiness = score[0][1]\n",
    "    neutral = score[0][2]\n",
    "    sadness = score[0][3]\n",
    "    worry = score[0][4]\n",
    "\n",
    "    result = {\n",
    "        \"date_time\": date_time,\n",
    "        \"tweet\": tweet,\n",
    "        \"link\": link,\n",
    "        \"state\": state,\n",
    "        \"city\": city,\n",
    "        \"anger\": anger,\n",
    "        \"happiness\": happiness,\n",
    "        \"neutral\": neutral,\n",
    "        \"sadness\": sadness,\n",
    "        \"worry\": worry,\n",
    "    }\n",
    "\n",
    "    output = output.append(result, ignore_index=True)\n",
    "\n",
    "output[\n",
    "    [\n",
    "        \"date_time\",\n",
    "        \"tweet\",\n",
    "        \"link\",\n",
    "        \"state\",\n",
    "        \"city\",\n",
    "        \"anger\",\n",
    "        \"happiness\",\n",
    "        \"neutral\",\n",
    "        \"sadness\",\n",
    "        \"worry\",\n",
    "    ]\n",
    "].to_csv(\"{}-backup.csv\".format(datetime.date.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_url = '#'\n",
    "myclient = pymongo.MongoClient(mongo_url)\n",
    "mydb = myclient[\"covidian\"]\n",
    "\n",
    "mycol = mydb[\"sentiments\"]\n",
    "df_for_sentiments = output[\n",
    "    [\n",
    "        \"date_time\",\n",
    "        \"tweet\",\n",
    "        \"link\",\n",
    "        \"state\",\n",
    "        \"city\",\n",
    "        \"anger\",\n",
    "        \"happiness\",\n",
    "        \"neutral\",\n",
    "        \"sadness\",\n",
    "        \"worry\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "for i, row in df_for_sentiments.iterrows():\n",
    "    mycol.insert_one(dict(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiments City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycol = mydb[\"sentiments_city\"]\n",
    "df_for_sentiments_city = (\n",
    "    output[\n",
    "        [\n",
    "            \"date_time\",\n",
    "            \"tweet\",\n",
    "            \"link\",\n",
    "            \"state\",\n",
    "            \"city\",\n",
    "            \"anger\",\n",
    "            \"happiness\",\n",
    "            \"neutral\",\n",
    "            \"sadness\",\n",
    "            \"worry\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby([\"state\", \"city\"], as_index=False)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "for i, row in df_for_sentiments_city.iterrows():\n",
    "    mycol.insert_one(dict(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiments State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycol = mydb[\"sentiments_state\"]\n",
    "df_for_sentiments_state = (\n",
    "    output[\n",
    "        [\n",
    "            \"date_time\",\n",
    "            \"tweet\",\n",
    "            \"link\",\n",
    "            \"state\",\n",
    "            \"city\",\n",
    "            \"anger\",\n",
    "            \"happiness\",\n",
    "            \"neutral\",\n",
    "            \"sadness\",\n",
    "            \"worry\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby([\"state\"], as_index=False)\n",
    "    .mean()\n",
    ")\n",
    "for i, row in df_for_sentiments_state.iterrows():\n",
    "    mycol.insert_one(dict(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x6d307d280>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycol = mydb[\"sentiments_country\"]\n",
    "df_for_sentiments_country = output[\n",
    "    [\n",
    "        \"date_time\",\n",
    "        \"tweet\",\n",
    "        \"link\",\n",
    "        \"state\",\n",
    "        \"city\",\n",
    "        \"anger\",\n",
    "        \"happiness\",\n",
    "        \"neutral\",\n",
    "        \"sadness\",\n",
    "        \"worry\",\n",
    "    ]\n",
    "].mean()\n",
    "sentiments_country = dict()\n",
    "sentiments_country[\"country\"] = \"India\"\n",
    "sentiments_country.update(df_for_sentiments_country.to_dict())\n",
    "mycol.insert_one(sentiments_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
