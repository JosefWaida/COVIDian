{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import nltk\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import 5 emotions training csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>labels</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>we want to trade with someone who has houston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>worry</td>\n",
       "      <td>repinging  why didnt you go to prom bc my bf d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>worry</td>\n",
       "      <td>hmmm httpwwwdjherocom is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>sadness</td>\n",
       "      <td>charlene my love i miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>sadness</td>\n",
       "      <td>im sorry  at least its friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19950</th>\n",
       "      <td>19950</td>\n",
       "      <td>31250</td>\n",
       "      <td>happiness</td>\n",
       "      <td>succesfully following tayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951</th>\n",
       "      <td>19951</td>\n",
       "      <td>31251</td>\n",
       "      <td>love</td>\n",
       "      <td>happy mothers day  all my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19952</th>\n",
       "      <td>19952</td>\n",
       "      <td>31252</td>\n",
       "      <td>love</td>\n",
       "      <td>happy mothers day to all the mommies out there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19953</th>\n",
       "      <td>19953</td>\n",
       "      <td>31253</td>\n",
       "      <td>happiness</td>\n",
       "      <td>wassup beautiful follow me  peep out my new h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19954</th>\n",
       "      <td>19954</td>\n",
       "      <td>31254</td>\n",
       "      <td>love</td>\n",
       "      <td>bullet train from tokyo    the gf and i have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19955 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index     labels  \\\n",
       "0               0      2    neutral   \n",
       "1               1      3      worry   \n",
       "2               2      5      worry   \n",
       "3               3      6    sadness   \n",
       "4               4      7    sadness   \n",
       "...           ...    ...        ...   \n",
       "19950       19950  31250  happiness   \n",
       "19951       19951  31251       love   \n",
       "19952       19952  31252       love   \n",
       "19953       19953  31253  happiness   \n",
       "19954       19954  31254       love   \n",
       "\n",
       "                                                   tweet  \n",
       "0       we want to trade with someone who has houston...  \n",
       "1      repinging  why didnt you go to prom bc my bf d...  \n",
       "2                          hmmm httpwwwdjherocom is down  \n",
       "3                            charlene my love i miss you  \n",
       "4                          im sorry  at least its friday  \n",
       "...                                                  ...  \n",
       "19950                        succesfully following tayla  \n",
       "19951                     happy mothers day  all my love  \n",
       "19952  happy mothers day to all the mommies out there...  \n",
       "19953   wassup beautiful follow me  peep out my new h...  \n",
       "19954   bullet train from tokyo    the gf and i have ...  \n",
       "\n",
       "[19955 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Shibbs\\Desktop\\Projects\\Sentiment analysis\\My dataset\\5emotions_final.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['index', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>we want to trade with someone who has houston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worry</td>\n",
       "      <td>repinging  why didnt you go to prom bc my bf d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worry</td>\n",
       "      <td>hmmm  is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>charlene my love i miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sadness</td>\n",
       "      <td>im sorry  at least its friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19950</th>\n",
       "      <td>happiness</td>\n",
       "      <td>succesfully following tayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951</th>\n",
       "      <td>love</td>\n",
       "      <td>happy mothers day  all my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19952</th>\n",
       "      <td>love</td>\n",
       "      <td>happy mothers day to all the mommies out there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19953</th>\n",
       "      <td>happiness</td>\n",
       "      <td>wassup beautiful follow me  peep out my new h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19954</th>\n",
       "      <td>love</td>\n",
       "      <td>bullet train from tokyo    the gf and i have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19955 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          labels                                              tweet\n",
       "0        neutral   we want to trade with someone who has houston...\n",
       "1          worry  repinging  why didnt you go to prom bc my bf d...\n",
       "2          worry                                      hmmm  is down\n",
       "3        sadness                        charlene my love i miss you\n",
       "4        sadness                      im sorry  at least its friday\n",
       "...          ...                                                ...\n",
       "19950  happiness                        succesfully following tayla\n",
       "19951       love                     happy mothers day  all my love\n",
       "19952       love  happy mothers day to all the mommies out there...\n",
       "19953  happiness   wassup beautiful follow me  peep out my new h...\n",
       "19954       love   bullet train from tokyo    the gf and i have ...\n",
       "\n",
       "[19955 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].str.replace('http\\S+|www.\\S+', '', case=False) # Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-64ed3b75643c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mremove_punct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shibbs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3848\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-64ed3b75643c>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mremove_punct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-64ed3b75643c>\u001b[0m in \u001b[0;36mremove_punct\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#text = re.sub('[0-9]+', '', text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtext\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    \n",
    "    #text = re.sub('[0-9]+', '', text)\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])    \n",
    "    return text.lower()\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: remove_punct(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      4088\n",
       "worry        4056\n",
       "happiness    4008\n",
       "sadness      3962\n",
       "love         3841\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''neutral_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if df['labels'][index] == 'sadness':\n",
    "        neutral_list.append(index)'''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import random\n",
    "\n",
    "random.shuffle(neutral_list)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df = df.drop(neutral_list[:1200])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    desc = row['tweet']\n",
    "    list.append(str(desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for index, row in df.iterrows():\n",
    "    desc = row['tweet']\n",
    "    list.append(\" \".join(re.findall(\"[a-zA-Z]+\", str(desc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df = df.reset_index()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('5emotions_final_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLength = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "print(maxLength )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list)\n",
    "x = tokenizer.texts_to_sequences(list)\n",
    "x = pad_sequences(x, maxlen=maxLength, padding='pre', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df['labels']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 57, 512)           11019264  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 57, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 55, 512)           786944    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 23, 256)           655616    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 11, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 11, 128)           197120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 12,708,677\n",
      "Trainable params: 12,708,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import SpatialDropout1D, Dropout\n",
    "import keras\n",
    "#from keras.layers import Conv1D, MaxPooling1D\n",
    "embedding_input = len(tokenizer.word_index) + 1\n",
    "model = Sequential()\n",
    "model.add(Embedding(embedding_input, 512, input_length = maxLength))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(Conv1D(512,\n",
    "                 3,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(256,\n",
    "                 5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "'''model.add(Conv1D(128,\n",
    "                 7,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))'''\n",
    "#model.add(Conv1D(512, 3, padding='valid', activation='relu',strides=1))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(Bidirectional(LSTM(64, dropout=0.2)))\n",
    "#model.add(LSTM(32, dropout = 0.2, return_sequences=True)) # returns a sequence of vectors of dimension 32\n",
    "#model.add(LSTM(128, return_sequences=True, dropout = 0.7))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(128, dropout = 0.7, recurrent_dropout = 0.7, return_sequences=True))\n",
    "#model.add(LSTM(64, dropout = 0.5, recurrent_dropout = 0.5, return_sequences=True))\n",
    "model.add(LSTM(64, dropout = 0.7, recurrent_dropout = 0.7))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(LSTM(128))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Bidirectional(LSTM(64, dropout=0.5)))\n",
    "#model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(Dense(16,activation='relu'))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "#optimizer = keras.optimizers.Adam(lr=0.0009)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shibbs\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15964 samples, validate on 3991 samples\n",
      "Epoch 1/20\n",
      "15964/15964 [==============================] - 58s 4ms/step - loss: 1.5834 - accuracy: 0.2556 - val_loss: 1.4814 - val_accuracy: 0.3325\n",
      "Epoch 2/20\n",
      "15964/15964 [==============================] - 56s 4ms/step - loss: 1.4541 - accuracy: 0.3548 - val_loss: 1.4817 - val_accuracy: 0.3473\n",
      "Epoch 3/20\n",
      "15964/15964 [==============================] - 56s 4ms/step - loss: 1.3370 - accuracy: 0.4029 - val_loss: 1.5313 - val_accuracy: 0.3475\n",
      "Epoch 4/20\n",
      "15964/15964 [==============================] - 56s 3ms/step - loss: 1.2292 - accuracy: 0.4510 - val_loss: 1.6489 - val_accuracy: 0.3418\n",
      "Epoch 5/20\n",
      "15964/15964 [==============================] - 56s 4ms/step - loss: 1.1444 - accuracy: 0.4914 - val_loss: 1.7025 - val_accuracy: 0.3408\n",
      "Epoch 6/20\n",
      "15964/15964 [==============================] - 56s 4ms/step - loss: 1.0475 - accuracy: 0.5480 - val_loss: 1.8251 - val_accuracy: 0.3358\n",
      "Epoch 7/20\n",
      "15964/15964 [==============================] - 57s 4ms/step - loss: 0.9648 - accuracy: 0.5956 - val_loss: 1.8863 - val_accuracy: 0.3420\n",
      "Epoch 8/20\n",
      "15964/15964 [==============================] - 57s 4ms/step - loss: 0.8866 - accuracy: 0.6384 - val_loss: 2.0009 - val_accuracy: 0.3398\n",
      "Epoch 9/20\n",
      "15964/15964 [==============================] - 58s 4ms/step - loss: 0.8162 - accuracy: 0.6772 - val_loss: 2.0767 - val_accuracy: 0.3440\n",
      "Epoch 10/20\n",
      "15964/15964 [==============================] - 58s 4ms/step - loss: 0.7504 - accuracy: 0.7115 - val_loss: 2.2102 - val_accuracy: 0.3363\n",
      "Epoch 11/20\n",
      "15964/15964 [==============================] - 58s 4ms/step - loss: 0.6796 - accuracy: 0.7434 - val_loss: 2.3802 - val_accuracy: 0.3345\n",
      "Epoch 12/20\n",
      "15964/15964 [==============================] - 59s 4ms/step - loss: 0.6263 - accuracy: 0.7650 - val_loss: 2.4999 - val_accuracy: 0.3302\n",
      "Epoch 13/20\n",
      "15964/15964 [==============================] - 59s 4ms/step - loss: 0.5861 - accuracy: 0.7855 - val_loss: 2.6139 - val_accuracy: 0.3230\n",
      "Epoch 14/20\n",
      "15964/15964 [==============================] - 59s 4ms/step - loss: 0.5406 - accuracy: 0.8019 - val_loss: 2.7577 - val_accuracy: 0.3287\n",
      "Epoch 15/20\n",
      "15964/15964 [==============================] - 60s 4ms/step - loss: 0.5155 - accuracy: 0.8134 - val_loss: 2.6981 - val_accuracy: 0.3315\n",
      "Epoch 16/20\n",
      "15964/15964 [==============================] - 60s 4ms/step - loss: 0.4904 - accuracy: 0.8215 - val_loss: 2.7457 - val_accuracy: 0.3280\n",
      "Epoch 17/20\n",
      "15964/15964 [==============================] - 60s 4ms/step - loss: 0.4753 - accuracy: 0.8307 - val_loss: 2.8792 - val_accuracy: 0.3297\n",
      "Epoch 18/20\n",
      "15964/15964 [==============================] - 60s 4ms/step - loss: 0.4541 - accuracy: 0.8364 - val_loss: 2.9284 - val_accuracy: 0.3332\n",
      "Epoch 19/20\n",
      "15964/15964 [==============================] - 61s 4ms/step - loss: 0.4276 - accuracy: 0.8484 - val_loss: 3.1363 - val_accuracy: 0.3285\n",
      "Epoch 20/20\n",
      "15964/15964 [==============================] - 61s 4ms/step - loss: 0.4208 - accuracy: 0.8509 - val_loss: 3.0926 - val_accuracy: 0.3343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x258af05bc08>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 20,  batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 57, 256)           5764352   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 57, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 55, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 27, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 23, 128)           163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5, 64)             57408     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 2, 64)             24768     \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 2, 32)             9312      \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 16)                2352      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 6,219,109\n",
      "Trainable params: 6,219,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SpatialDropout1D, Dropout\n",
    "import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "embedding_input = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(embedding_input, 256, input_length = maxLength))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(Conv1D(256,\n",
    "                 3,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(128,\n",
    "                 5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(64,\n",
    "                 7,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Conv1D(512, 3, padding='valid', activation='relu',strides=1))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(Bidirectional(LSTM(64, dropout=0.2)))\n",
    "#model.add(LSTM(32, dropout = 0.2, return_sequences=True)) # returns a sequence of vectors of dimension 32\n",
    "#model.add(LSTM(128, return_sequences=True, dropout = 0.7))  # returns a sequence of vectors of dimension 32\n",
    "model.add(GRU(64, dropout = 0.5, recurrent_dropout = 0.5, return_sequences=True))\n",
    "model.add(GRU(32, dropout = 0.5, recurrent_dropout = 0.5, return_sequences=True))\n",
    "model.add(GRU(16, dropout = 0.5, recurrent_dropout = 0.5))\n",
    "#model.add(Bidirectional(LSTM(64, dropout=0.5)))\n",
    "#model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(Dense(16,activation='relu'))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "#optimizer = keras.optimizers.Adam(lr=0.0007)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15964 samples, validate on 3991 samples\n",
      "Epoch 1/20\n",
      "15964/15964 [==============================] - 39s 2ms/step - loss: 1.6088 - accuracy: 0.2114 - val_loss: 1.5986 - val_accuracy: 0.2440\n",
      "Epoch 2/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.5958 - accuracy: 0.2442 - val_loss: 1.5967 - val_accuracy: 0.2483\n",
      "Epoch 3/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.5673 - accuracy: 0.2781 - val_loss: 1.6062 - val_accuracy: 0.2543\n",
      "Epoch 4/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.5135 - accuracy: 0.3075 - val_loss: 1.6332 - val_accuracy: 0.2603\n",
      "Epoch 5/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.4401 - accuracy: 0.3488 - val_loss: 1.6492 - val_accuracy: 0.2749\n",
      "Epoch 6/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.3494 - accuracy: 0.3921 - val_loss: 1.7040 - val_accuracy: 0.2826\n",
      "Epoch 7/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.2750 - accuracy: 0.4261 - val_loss: 1.8235 - val_accuracy: 0.2471\n",
      "Epoch 8/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.2146 - accuracy: 0.4525 - val_loss: 1.8613 - val_accuracy: 0.2886\n",
      "Epoch 9/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.1572 - accuracy: 0.4822 - val_loss: 1.9374 - val_accuracy: 0.2957\n",
      "Epoch 10/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.1156 - accuracy: 0.4976 - val_loss: 1.9924 - val_accuracy: 0.2959\n",
      "Epoch 11/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.0774 - accuracy: 0.5185 - val_loss: 2.0868 - val_accuracy: 0.2701\n",
      "Epoch 12/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.0497 - accuracy: 0.5271 - val_loss: 2.1613 - val_accuracy: 0.2779\n",
      "Epoch 13/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 1.0200 - accuracy: 0.5395 - val_loss: 2.1907 - val_accuracy: 0.2879\n",
      "Epoch 14/20\n",
      "15964/15964 [==============================] - 36s 2ms/step - loss: 1.0009 - accuracy: 0.5409 - val_loss: 2.1747 - val_accuracy: 0.2824\n",
      "Epoch 15/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 0.9800 - accuracy: 0.5489 - val_loss: 2.2685 - val_accuracy: 0.2769\n",
      "Epoch 16/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 0.9665 - accuracy: 0.5571 - val_loss: 2.2534 - val_accuracy: 0.2786\n",
      "Epoch 17/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 0.9473 - accuracy: 0.5656 - val_loss: 2.3620 - val_accuracy: 0.2836\n",
      "Epoch 18/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 0.9397 - accuracy: 0.5687 - val_loss: 2.3585 - val_accuracy: 0.2884\n",
      "Epoch 19/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 0.9335 - accuracy: 0.5710 - val_loss: 2.3950 - val_accuracy: 0.2846\n",
      "Epoch 20/20\n",
      "15964/15964 [==============================] - 35s 2ms/step - loss: 0.9221 - accuracy: 0.5735 - val_loss: 2.4038 - val_accuracy: 0.2819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ad503a4d88>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 20,  batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_lstm_gpu1_7.2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import cleaned csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(r'C:\\Users\\Shibbs\\Desktop\\Projects\\Sentiment analysis\\My dataset\\mumbai_cleaned_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['#coronavirus', '#missionbeginagain', '#unloc...</td>\n",
       "      <td>https://twitter.com/mumbaimatterz/status/12732...</td>\n",
       "      <td>mumbai coronavirus updates missionbeginagain u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['#covid19india', '#unlock2', '#mumbai', '#unl...</td>\n",
       "      <td>https://twitter.com/yogeshsakh/status/12732559...</td>\n",
       "      <td>seeing the current covid india situation and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['#covidー19', '#coronavirus', '#maharashtrafig...</td>\n",
       "      <td>https://twitter.com/Maha_MEDD/status/127320617...</td>\n",
       "      <td>a map prepared by csir neeri mumbai showing co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['#unlock1', '#mumbai']</td>\n",
       "      <td>https://twitter.com/theprasannata/status/12731...</td>\n",
       "      <td>i think probably us young people in the office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['#missionbeginagain', '#mumbai', '#unlock1']</td>\n",
       "      <td>https://twitter.com/mumbaiat24am/status/127318...</td>\n",
       "      <td>missionbeginagain mumbai crowds surge on day o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>['#covid_19india', '#mumbai', '#socialdistanci...</td>\n",
       "      <td>https://twitter.com/MonilDalal/status/12699036...</td>\n",
       "      <td>government has started the economy but citizen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>['#coronapandemic', '#mumbai', '#mumbaikars', ...</td>\n",
       "      <td>https://twitter.com/NBhalwankar/status/1269896...</td>\n",
       "      <td>another shocker how can the coronapandemic get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>['#mumbai', '#monday', '#mondayblues', '#monda...</td>\n",
       "      <td>https://twitter.com/ompsyram/status/1269896580...</td>\n",
       "      <td>the new normal mumbai monday mondayblues monda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>['#unlock1', '#covid19india']</td>\n",
       "      <td>https://twitter.com/ScribeUpma/status/12698952...</td>\n",
       "      <td>mumbai on work mode unlock covid india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>['#mumbai', '#corporate', '#security', '#mumba...</td>\n",
       "      <td>https://twitter.com/pareshoswal70/status/12698...</td>\n",
       "      <td>is our mumbai safe the real mumbai start no so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              hashtags  \\\n",
       "0    ['#coronavirus', '#missionbeginagain', '#unloc...   \n",
       "1    ['#covid19india', '#unlock2', '#mumbai', '#unl...   \n",
       "2    ['#covidー19', '#coronavirus', '#maharashtrafig...   \n",
       "3                              ['#unlock1', '#mumbai']   \n",
       "4        ['#missionbeginagain', '#mumbai', '#unlock1']   \n",
       "..                                                 ...   \n",
       "353  ['#covid_19india', '#mumbai', '#socialdistanci...   \n",
       "354  ['#coronapandemic', '#mumbai', '#mumbaikars', ...   \n",
       "355  ['#mumbai', '#monday', '#mondayblues', '#monda...   \n",
       "356                      ['#unlock1', '#covid19india']   \n",
       "357  ['#mumbai', '#corporate', '#security', '#mumba...   \n",
       "\n",
       "                                                  link  \\\n",
       "0    https://twitter.com/mumbaimatterz/status/12732...   \n",
       "1    https://twitter.com/yogeshsakh/status/12732559...   \n",
       "2    https://twitter.com/Maha_MEDD/status/127320617...   \n",
       "3    https://twitter.com/theprasannata/status/12731...   \n",
       "4    https://twitter.com/mumbaiat24am/status/127318...   \n",
       "..                                                 ...   \n",
       "353  https://twitter.com/MonilDalal/status/12699036...   \n",
       "354  https://twitter.com/NBhalwankar/status/1269896...   \n",
       "355  https://twitter.com/ompsyram/status/1269896580...   \n",
       "356  https://twitter.com/ScribeUpma/status/12698952...   \n",
       "357  https://twitter.com/pareshoswal70/status/12698...   \n",
       "\n",
       "                                                 tweet  \n",
       "0    mumbai coronavirus updates missionbeginagain u...  \n",
       "1    seeing the current covid india situation and t...  \n",
       "2    a map prepared by csir neeri mumbai showing co...  \n",
       "3    i think probably us young people in the office...  \n",
       "4    missionbeginagain mumbai crowds surge on day o...  \n",
       "..                                                 ...  \n",
       "353  government has started the economy but citizen...  \n",
       "354  another shocker how can the coronapandemic get...  \n",
       "355  the new normal mumbai monday mondayblues monda...  \n",
       "356             mumbai on work mode unlock covid india  \n",
       "357  is our mumbai safe the real mumbai start no so...  \n",
       "\n",
       "[358 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(dataframe):\n",
    "    \n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    preds = []\n",
    "\n",
    "    for index,row in dataframe.iterrows():\n",
    "        desc = row['tweet']\n",
    "        list1.append(desc)\n",
    "        \n",
    "    for i in list1:\n",
    "        \n",
    "        list1 = pad_sequences(tokenizer.texts_to_sequences([i]), truncating='post', maxlen=maxLength)\n",
    "        score = model.predict([list1])\n",
    "        preds.append(score)\n",
    "        emotions = np.array(preds)\n",
    "        \n",
    "    for i in range(0, len(emotions)):\n",
    "        if np.argmax(emotions[i][0]) == 0:\n",
    "            list2.append('happiness')\n",
    "        elif np.argmax(emotions[i][0]) == 1:\n",
    "            list2.append('joy')\n",
    "        elif np.argmax(emotions[i][0]) == 2:\n",
    "            list2.append('neutral')\n",
    "        elif np.argmax(emotions[i][0]) == 3:  \n",
    "            list2.append('sadness')\n",
    "        elif np.argmax(emotions[i][0]) == 4:\n",
    "            list2.append('worry')\n",
    "        \n",
    "    \n",
    "    return list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = prediction(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['#coronavirus', '#missionbeginagain', '#unloc...</td>\n",
       "      <td>https://twitter.com/mumbaimatterz/status/12732...</td>\n",
       "      <td>mumbai coronavirus updates missionbeginagain u...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['#covid19india', '#unlock2', '#mumbai', '#unl...</td>\n",
       "      <td>https://twitter.com/yogeshsakh/status/12732559...</td>\n",
       "      <td>seeing the current covid india situation and t...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['#covidー19', '#coronavirus', '#maharashtrafig...</td>\n",
       "      <td>https://twitter.com/Maha_MEDD/status/127320617...</td>\n",
       "      <td>a map prepared by csir neeri mumbai showing co...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['#unlock1', '#mumbai']</td>\n",
       "      <td>https://twitter.com/theprasannata/status/12731...</td>\n",
       "      <td>i think probably us young people in the office...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['#missionbeginagain', '#mumbai', '#unlock1']</td>\n",
       "      <td>https://twitter.com/mumbaiat24am/status/127318...</td>\n",
       "      <td>missionbeginagain mumbai crowds surge on day o...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>['#covid_19india', '#mumbai', '#socialdistanci...</td>\n",
       "      <td>https://twitter.com/MonilDalal/status/12699036...</td>\n",
       "      <td>government has started the economy but citizen...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>['#coronapandemic', '#mumbai', '#mumbaikars', ...</td>\n",
       "      <td>https://twitter.com/NBhalwankar/status/1269896...</td>\n",
       "      <td>another shocker how can the coronapandemic get...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>['#mumbai', '#monday', '#mondayblues', '#monda...</td>\n",
       "      <td>https://twitter.com/ompsyram/status/1269896580...</td>\n",
       "      <td>the new normal mumbai monday mondayblues monda...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>['#unlock1', '#covid19india']</td>\n",
       "      <td>https://twitter.com/ScribeUpma/status/12698952...</td>\n",
       "      <td>mumbai on work mode unlock covid india</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>['#mumbai', '#corporate', '#security', '#mumba...</td>\n",
       "      <td>https://twitter.com/pareshoswal70/status/12698...</td>\n",
       "      <td>is our mumbai safe the real mumbai start no so...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              hashtags  \\\n",
       "0    ['#coronavirus', '#missionbeginagain', '#unloc...   \n",
       "1    ['#covid19india', '#unlock2', '#mumbai', '#unl...   \n",
       "2    ['#covidー19', '#coronavirus', '#maharashtrafig...   \n",
       "3                              ['#unlock1', '#mumbai']   \n",
       "4        ['#missionbeginagain', '#mumbai', '#unlock1']   \n",
       "..                                                 ...   \n",
       "353  ['#covid_19india', '#mumbai', '#socialdistanci...   \n",
       "354  ['#coronapandemic', '#mumbai', '#mumbaikars', ...   \n",
       "355  ['#mumbai', '#monday', '#mondayblues', '#monda...   \n",
       "356                      ['#unlock1', '#covid19india']   \n",
       "357  ['#mumbai', '#corporate', '#security', '#mumba...   \n",
       "\n",
       "                                                  link  \\\n",
       "0    https://twitter.com/mumbaimatterz/status/12732...   \n",
       "1    https://twitter.com/yogeshsakh/status/12732559...   \n",
       "2    https://twitter.com/Maha_MEDD/status/127320617...   \n",
       "3    https://twitter.com/theprasannata/status/12731...   \n",
       "4    https://twitter.com/mumbaiat24am/status/127318...   \n",
       "..                                                 ...   \n",
       "353  https://twitter.com/MonilDalal/status/12699036...   \n",
       "354  https://twitter.com/NBhalwankar/status/1269896...   \n",
       "355  https://twitter.com/ompsyram/status/1269896580...   \n",
       "356  https://twitter.com/ScribeUpma/status/12698952...   \n",
       "357  https://twitter.com/pareshoswal70/status/12698...   \n",
       "\n",
       "                                                 tweet  sentiment  \n",
       "0    mumbai coronavirus updates missionbeginagain u...  happiness  \n",
       "1    seeing the current covid india situation and t...      worry  \n",
       "2    a map prepared by csir neeri mumbai showing co...      worry  \n",
       "3    i think probably us young people in the office...    sadness  \n",
       "4    missionbeginagain mumbai crowds surge on day o...    neutral  \n",
       "..                                                 ...        ...  \n",
       "353  government has started the economy but citizen...        joy  \n",
       "354  another shocker how can the coronapandemic get...  happiness  \n",
       "355  the new normal mumbai monday mondayblues monda...    sadness  \n",
       "356             mumbai on work mode unlock covid india        joy  \n",
       "357  is our mumbai safe the real mumbai start no so...      worry  \n",
       "\n",
       "[358 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worry        117\n",
       "neutral      113\n",
       "happiness     49\n",
       "sadness       49\n",
       "joy           30\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with newspaper distribution in mumbai slowly coming back to normal how soon would you restart your physical copy subscription newspaper mumbai covid lockdown unlock mumbainews media\n",
      "happiness\n"
     ]
    }
   ],
   "source": [
    "index = 12\n",
    "\n",
    "print(df0['tweet'][index])\n",
    "print(df0['sentiment'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.to_csv(r'C:\\Users\\Shibbs\\Desktop\\Projects\\Sentiment analysis\\My dataset\\cnn_lstm1_7.2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
